{
  "providers": {
    "openai": {
      "name": "OpenAI",
      "requires_api_key": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "pip_install": "openai",
      "env_var": "OPENAI_API_KEY",
      "default_model": "gpt-4o-mini",
      "api_base": "https://api.openai.com/v1",
      "models": {
        "gpt-4o": {
          "context_window": 128000,
          "cost_per_1k_input_tokens": 0.005,
          "cost_per_1k_output_tokens": 0.015
        },
        "gpt-4o-mini": {
          "context_window": 128000,
          "cost_per_1k_input_tokens": 0.00015,
          "cost_per_1k_output_tokens": 0.0006
        }
      }
    },
    "anthropic": {
      "name": "Anthropic",
      "requires_api_key": true,
      "supports_streaming": true,
      "supports_function_calling": false,
      "pip_install": "anthropic",
      "env_var": "ANTHROPIC_API_KEY",
      "default_model": "claude-3-haiku-20240307",
      "api_base": "https://api.anthropic.com/v1",
      "models": {
        "claude-3-opus-20240229": {
          "context_window": 200000,
          "cost_per_1k_input_tokens": 0.015,
          "cost_per_1k_output_tokens": 0.075
        },
        "claude-3-sonnet-20240229": {
          "context_window": 200000,
          "cost_per_1k_input_tokens": 0.003,
          "cost_per_1k_output_tokens": 0.015
        },
        "claude-3-haiku-20240307": {
          "context_window": 200000,
          "cost_per_1k_input_tokens": 0.00025,
          "cost_per_1k_output_tokens": 0.00125
        }
      }
    },
    "openrouter": {
      "name": "OpenRouter",
      "requires_api_key": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "pip_install": null,
      "env_var": "OPENROUTER_API_KEY",
      "default_model": "openai/gpt-3.5-turbo",
      "api_base": "https://openrouter.ai/api/v1",
      "models": {
        "openai/gpt-4": {
          "context_window": 8192,
          "cost_per_1k_input_tokens": 0.03,
          "cost_per_1k_output_tokens": 0.06
        },
        "openai/gpt-3.5-turbo": {
          "context_window": 16385,
          "cost_per_1k_input_tokens": 0.001,
          "cost_per_1k_output_tokens": 0.002
        },
        "anthropic/claude-3-haiku": {
          "context_window": 200000,
          "cost_per_1k_input_tokens": 0.00025,
          "cost_per_1k_output_tokens": 0.00125
        },
        "google/gemini-2.5-flash": {
          "context_window": 1000000,
          "cost_per_1k_input_tokens": 0.000075,
          "cost_per_1k_output_tokens": 0.0003
        },
        "deepseek/deepseek-chat": {
          "context_window": 64000,
          "cost_per_1k_input_tokens": 0.00014,
          "cost_per_1k_output_tokens": 0.00028
        },
        "mistralai/mistral-7b-instruct": {
          "context_window": 32768,
          "cost_per_1k_input_tokens": 0,
          "cost_per_1k_output_tokens": 0
        }
      }
    },
    "ollama": {
      "name": "Ollama",
      "requires_api_key": false,
      "supports_streaming": true,
      "supports_function_calling": false,
      "pip_install": null,
      "env_var": null,
      "default_model": "llama2",
      "api_base": "http://localhost:11434",
      "notes": "Requires Ollama server running locally",
      "models": {
        "llama2": {
          "context_window": 4096,
          "cost_per_1k_input_tokens": 0,
          "cost_per_1k_output_tokens": 0
        },
        "mistral": {
          "context_window": 8192,
          "cost_per_1k_input_tokens": 0,
          "cost_per_1k_output_tokens": 0
        },
        "codellama": {
          "context_window": 4096,
          "cost_per_1k_input_tokens": 0,
          "cost_per_1k_output_tokens": 0
        },
        "deepseek-coder": {
          "context_window": 16384,
          "cost_per_1k_input_tokens": 0,
          "cost_per_1k_output_tokens": 0
        }
      }
    },
    "llamacpp": {
      "name": "Llama.cpp",
      "requires_api_key": false,
      "supports_streaming": true,
      "supports_function_calling": false,
      "pip_install": "llama-cpp-python",
      "env_var": null,
      "notes": "Requires local model file (GGUF format)",
      "models": {
        "local": {
          "context_window": 4096,
          "cost_per_1k_input_tokens": 0,
          "cost_per_1k_output_tokens": 0,
          "notes": "Depends on loaded model file"
        }
      }
    }
  },
  "last_updated": "2024-11-01",
  "version": "1.0.0"
}
