import json

import pytest
from aiohttp import client_exceptions
from typing import Callable

from codeconcat.ai.base import AIProviderConfig, AIProviderType
from codeconcat.ai.providers.local_server_provider import LocalServerProvider


class StubResponse:
    """Minimal aiohttp-like response context manager."""

    def __init__(self, status: int, payload: dict | None = None, text_body: str | None = None):
        self.status = status
        self._payload = payload
        self._text = text_body if text_body is not None else json.dumps(payload or {})

    async def __aenter__(self):
        return self

    async def __aexit__(self, exc_type, exc, tb):
        return False

    async def json(self):
        if self._payload is None:
            raise ValueError("No JSON payload set")
        return self._payload

    async def text(self):
        return self._text


class FakeSession:
    """Fake aiohttp session that serves pre-defined responses."""

    def __init__(
        self,
        routes: dict[tuple[str, str], StubResponse | Callable[[dict | None], StubResponse]],
    ):
        self._routes = routes

    def _resolve(self, method: str, url: str, payload: dict | None = None) -> StubResponse:
        responder = self._routes.get((method, url))
        if responder is None:
            return StubResponse(404, {"error": "not found"})
        if callable(responder):
            return responder(payload)
        return responder

    def get(self, url: str):
        return self._resolve("GET", url)

    def post(self, url: str, json: dict):
        return self._resolve("POST", url, payload=json)

    async def close(self):
        return None


class ErrorSession:
    """Session that always raises connector errors to simulate offline servers."""

    def get(self, url: str):  # noqa: ARG002 - interface matches aiohttp
        raise client_exceptions.ClientConnectorError(None, OSError("connection refused"))

    def post(self, url: str, json: dict):  # noqa: ARG002 - interface matches aiohttp
        raise client_exceptions.ClientConnectorError(None, OSError("connection refused"))

    async def close(self):
        return None


@pytest.mark.asyncio
@pytest.mark.parametrize(
    "provider_type, expected_kind",
    [
        (AIProviderType.VLLM, "vLLM"),
        (AIProviderType.LMSTUDIO, "LM Studio"),
        (AIProviderType.LLAMACPP_SERVER, "llama.cpp server"),
    ],
)
async def test_local_server_provider_auto_discovers_models(provider_type, expected_kind):
    api_base = "http://fake.local:8000"
    routes = {
        ("GET", f"{api_base}/health"): StubResponse(200, {"status": "ok"}),
        ("GET", f"{api_base}/v1/models"): StubResponse(
            200,
            {"data": [{"id": "model-A"}, {"id": "model-B"}]},
        ),
        ("POST", f"{api_base}/v1/chat/completions"): lambda payload: StubResponse(
            200,
            {
                "choices": [
                    {
                        "message": {
                            "content": f"Summary generated by {payload['model']}"
                        }
                    }
                ],
                "usage": {
                    "prompt_tokens": 12,
                    "completion_tokens": 4,
                    "total_tokens": 16,
                },
            },
        ),
    }

    config = AIProviderConfig(
        provider_type=provider_type,
        api_base=api_base,
        model="",
        cache_enabled=False,
    )
    provider = LocalServerProvider(config)
    provider._session = FakeSession(routes)

    try:
        assert await provider.validate_connection()
        assert provider.server_kind == expected_kind

        result = await provider.summarize_code("print('hello')", "python")
        assert result.summary.startswith("Summary generated")
        metadata = result.metadata
        assert isinstance(metadata, dict)
        assert metadata.get("server_kind") == expected_kind
        assert metadata.get("auto_discovered_model") == "model-A"
        assert provider.config.model == "model-A"
    finally:
        await provider.close()


@pytest.mark.asyncio
async def test_local_server_provider_fallbacks_to_chat_endpoint():
    api_base = "http://fake.local:1234"
    routes = {
        ("GET", f"{api_base}/healthz"): StubResponse(200, {"status": "ok"}),
        ("GET", f"{api_base}/models"): StubResponse(200, {"data": [{"id": "fallback-model"}]}),
        ("POST", f"{api_base}/v1/chat/completions"): StubResponse(404, {"error": "not found"}),
        ("POST", f"{api_base}/chat/completions"): StubResponse(
            200,
            {
                "choices": [{"message": {"content": "Fallback summary"}}],
                "usage": {"prompt_tokens": 4, "completion_tokens": 6},
            },
        ),
    }

    config = AIProviderConfig(
        provider_type=AIProviderType.LOCAL_SERVER,
        api_base=api_base,
        model="",
        cache_enabled=False,
    )
    provider = LocalServerProvider(config)
    provider._session = FakeSession(routes)

    try:
        assert await provider.validate_connection()

        result = await provider.summarize_code("def fn(): pass", "python")
        assert result.summary == "Fallback summary"
        metadata = result.metadata
        assert isinstance(metadata, dict)
        assert metadata.get("api_base") == api_base
        assert metadata.get("server_kind") == "local server"
        assert provider.config.model == "fallback-model"
    finally:
        await provider.close()


@pytest.mark.asyncio
async def test_local_server_provider_reports_validation_errors():
    api_base = "http://fake.local:4321"
    config = AIProviderConfig(
        provider_type=AIProviderType.LMSTUDIO,
        api_base=api_base,
        model="",
        cache_enabled=False,
    )
    provider = LocalServerProvider(config)
    provider._session = ErrorSession()

    try:
        success = await provider.validate_connection()
        assert not success
        assert provider.last_error is not None
        assert "LM Studio" in provider.last_error
    finally:
        await provider.close()
